{
    "changed": true,
    "cmd": "kubeadm init --token abcdef.0123456789abcdef --token-ttl 24h0m0s --apiserver-advertise-address 10.0.10.110 --apiserver-cert-extra-sans 10.40.1.90,master-k8s.dannytest.com --control-plane-endpoint master-k8s.dannytest.com --pod-network-cidr 10.23.0.0/16\n",
    "delta": "0:04:17.746091",
    "end": "2024-08-26 06:33:59.569735",
    "msg": "non-zero return code",
    "rc": 1,
    "start": "2024-08-26 06:29:41.823644",
    "stderr": "I0826 06:29:45.883689  129005 version.go:256] remote version is much newer: v1.31.0; falling back to: stable-1.29\nW0826 06:29:47.884670  129005 checks.go:835] detected that the sandbox image \"registry.k8s.io/pause:3.8\" of the container runtime is inconsistent with that used by kubeadm. It is recommended that using \"registry.k8s.io/pause:3.9\" as the CRI sandbox image.\nerror execution phase wait-control-plane: couldn't initialize a Kubernetes cluster\nTo see the stack trace of this error execute with --v=5 or higher",
    "stderr_lines": [
        "I0826 06:29:45.883689  129005 version.go:256] remote version is much newer: v1.31.0; falling back to: stable-1.29",
        "W0826 06:29:47.884670  129005 checks.go:835] detected that the sandbox image \"registry.k8s.io/pause:3.8\" of the container runtime is inconsistent with that used by kubeadm. It is recommended that using \"registry.k8s.io/pause:3.9\" as the CRI sandbox image.",
        "error execution phase wait-control-plane: couldn't initialize a Kubernetes cluster",
        "To see the stack trace of this error execute with --v=5 or higher"
    ],
    "stdout": "[init] Using Kubernetes version: v1.29.8\n[preflight] Running pre-flight checks\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local master-k8s.dannytest.com master-test] and IPs [10.96.0.1 10.0.10.110 10.40.1.90]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [localhost master-test] and IPs [10.0.10.110 127.0.0.1 ::1]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [localhost master-test] and IPs [10.0.10.110 127.0.0.1 ::1]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"super-admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Starting the kubelet\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[kubelet-check] Initial timeout of 40s passed.\n\nUnfortunately, an error has occurred:\n\ttimed out waiting for the condition\n\nThis error is likely caused by:\n\t- The kubelet is not running\n\t- The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)\n\nIf you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:\n\t- 'systemctl status kubelet'\n\t- 'journalctl -xeu kubelet'\n\nAdditionally, a control plane component may have crashed or exited when started by the container runtime.\nTo troubleshoot, list all containers using your preferred container runtimes CLI.\nHere is one example how you may list all running Kubernetes containers by using crictl:\n\t- 'crictl --runtime-endpoint unix:///var/run/containerd/containerd.sock ps -a | grep kube | grep -v pause'\n\tOnce you have found the failing container, you can inspect its logs with:\n\t- 'crictl --runtime-endpoint unix:///var/run/containerd/containerd.sock logs CONTAINERID'",
    "stdout_lines": [
        "[init] Using Kubernetes version: v1.29.8",
        "[preflight] Running pre-flight checks",
        "[preflight] Pulling images required for setting up a Kubernetes cluster",
        "[preflight] This might take a minute or two, depending on the speed of your internet connection",
        "[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'",
        "[certs] Using certificateDir folder \"/etc/kubernetes/pki\"",
        "[certs] Generating \"ca\" certificate and key",
        "[certs] Generating \"apiserver\" certificate and key",
        "[certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local master-k8s.dannytest.com master-test] and IPs [10.96.0.1 10.0.10.110 10.40.1.90]",
        "[certs] Generating \"apiserver-kubelet-client\" certificate and key",
        "[certs] Generating \"front-proxy-ca\" certificate and key",
        "[certs] Generating \"front-proxy-client\" certificate and key",
        "[certs] Generating \"etcd/ca\" certificate and key",
        "[certs] Generating \"etcd/server\" certificate and key",
        "[certs] etcd/server serving cert is signed for DNS names [localhost master-test] and IPs [10.0.10.110 127.0.0.1 ::1]",
        "[certs] Generating \"etcd/peer\" certificate and key",
        "[certs] etcd/peer serving cert is signed for DNS names [localhost master-test] and IPs [10.0.10.110 127.0.0.1 ::1]",
        "[certs] Generating \"etcd/healthcheck-client\" certificate and key",
        "[certs] Generating \"apiserver-etcd-client\" certificate and key",
        "[certs] Generating \"sa\" key and public key",
        "[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"",
        "[kubeconfig] Writing \"admin.conf\" kubeconfig file",
        "[kubeconfig] Writing \"super-admin.conf\" kubeconfig file",
        "[kubeconfig] Writing \"kubelet.conf\" kubeconfig file",
        "[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file",
        "[kubeconfig] Writing \"scheduler.conf\" kubeconfig file",
        "[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"",
        "[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"",
        "[control-plane] Creating static Pod manifest for \"kube-apiserver\"",
        "[control-plane] Creating static Pod manifest for \"kube-controller-manager\"",
        "[control-plane] Creating static Pod manifest for \"kube-scheduler\"",
        "[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"",
        "[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"",
        "[kubelet-start] Starting the kubelet",
        "[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s",
        "[kubelet-check] Initial timeout of 40s passed.",
        "",
        "Unfortunately, an error has occurred:",
        "\ttimed out waiting for the condition",
        "",
        "This error is likely caused by:",
        "\t- The kubelet is not running",
        "\t- The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)",
        "",
        "If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:",
        "\t- 'systemctl status kubelet'",
        "\t- 'journalctl -xeu kubelet'",
        "",
        "Additionally, a control plane component may have crashed or exited when started by the container runtime.",
        "To troubleshoot, list all containers using your preferred container runtimes CLI.",
        "Here is one example how you may list all running Kubernetes containers by using crictl:",
        "\t- 'crictl --runtime-endpoint unix:///var/run/containerd/containerd.sock ps -a | grep kube | grep -v pause'",
        "\tOnce you have found the failing container, you can inspect its logs with:",
        "\t- 'crictl --runtime-endpoint unix:///var/run/containerd/containerd.sock logs CONTAINERID'"
    ]
}